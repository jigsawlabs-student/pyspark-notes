{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "boxed-scoop",
   "metadata": {},
   "source": [
    "# Spark DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-speaking",
   "metadata": {},
   "source": [
    "### Introducing a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-germany",
   "metadata": {},
   "source": [
    "The first step to creating a dataframe, is to initialize a spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sealed-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"films\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-cathedral",
   "metadata": {},
   "source": [
    "### Creating a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-benefit",
   "metadata": {},
   "source": [
    "To create our dataframe, we can start with a list of dictionaries in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "systematic-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [{'index': 1,\n",
    "  'title': 'Shazam!',\n",
    "  'release_date': 1553299200,\n",
    "  'genre': 'Comedy'}, {'index': 2,\n",
    "  'title': 'Captain Marvel',\n",
    "  'release_date': 1551830400,\n",
    "  'genre': 'Action'},  {'index': 3,\n",
    "  'title': 'Escape Room',\n",
    "  'release_date': 1546473600,\n",
    "  'genre': 'Horror'}, {'index': 4,\n",
    "  'title': 'How to Train A Dragon',\n",
    "  'release_date': 1546473600,\n",
    "  'genre': 'Animation'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "usual-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = spark.createDataFrame(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "musical-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------------+--------------------+\n",
      "|    genre|index|release_date|               title|\n",
      "+---------+-----+------------+--------------------+\n",
      "|   Comedy|    1|  1553299200|             Shazam!|\n",
      "|   Action|    2|  1551830400|      Captain Marvel|\n",
      "|   Horror|    3|  1546473600|         Escape Room|\n",
      "|Animation|    4|  1546473600|How to Train A Dr...|\n",
      "+---------+-----+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "settled-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genre: string (nullable = true)\n",
      " |-- index: long (nullable = true)\n",
      " |-- release_date: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-encoding",
   "metadata": {},
   "source": [
    "### From DataFrame to RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-conducting",
   "metadata": {},
   "source": [
    "Now a dataframe in Pyspark creates an RDD under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "focal-employment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[55] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "rapid-tractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(genre='Comedy', release_date=1553299200, title='Shazam!'),\n",
       " Row(genre='Action', release_date=1551830400, title='Captain Marvel'),\n",
       " Row(genre='Horror', release_date=1546473600, title='Escape Room'),\n",
       " Row(genre='Animation', release_date=1546473600, title='How to Train A Dragon')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-arbitration",
   "metadata": {},
   "source": [
    "1. It's distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-substance",
   "metadata": {},
   "source": [
    "And that even though this looks like a unified dataset, it's really distributed across different nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "equipped-bennett",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-immigration",
   "metadata": {},
   "source": [
    "2. It's lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "centered-onion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[60] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.rdd.map(lambda movie: movie['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "exterior-humidity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shazam!', 'Captain Marvel', 'Escape Room', 'How to Train A Dragon']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.rdd.map(lambda movie: movie['title']).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-cookbook",
   "metadata": {},
   "source": [
    "If we perform the equivalent operation with a dataframe, the operation is also treated as a transformation.  Let's see this.  Below, we'll select the `title` of each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "serial-there",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[title: string]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.select('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dangerous-melissa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|             Shazam!|\n",
      "|      Captain Marvel|\n",
      "|         Escape Room|\n",
      "|How to Train A Dr...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select('title').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-cooking",
   "metadata": {},
   "source": [
    "> So we can see that `show` is similar to `collect`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-standing",
   "metadata": {},
   "source": [
    "Let's do this one more time, this time with two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "funny-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|               title|    genre|\n",
      "+--------------------+---------+\n",
      "|             Shazam!|   Comedy|\n",
      "|      Captain Marvel|   Action|\n",
      "|         Escape Room|   Horror|\n",
      "|How to Train A Dr...|Animation|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select(['title', 'genre']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-yukon",
   "metadata": {},
   "source": [
    "> So to select multiple columns, we pass through a list of columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-france",
   "metadata": {},
   "source": [
    "4. Only Coarse Grained Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-laptop",
   "metadata": {},
   "source": [
    "Remember that with our RDDs, we only have coarse grained methods available to us -- those methods like `map` or `filter` that operate across a dataset.  This makes things a little tricky if we want to just select a single row.  For example, we may think that with our dataframe above, we want to select the entry at a specific index.  With our dataframe, the only way to do this is to use something akin to the filter method -- where we ask to *select* the rows that have an id of 1.  But we'll learn how to do that with our dataframe in a future lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-sleeping",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-roads",
   "metadata": {},
   "source": [
    "In this lesson we learned how to create a DataFrame in Spark.  We do so, not through our Spark context but by creating a Spark session.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bulgarian-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "verified-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = spark.createDataFrame(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-macintosh",
   "metadata": {},
   "source": [
    "We then saw that our dataframe is really just a simpler interface for interacting with our resilient distributed dataset.  And because of this, it contains the same features of our RDD: it's distributed, it's lazy, and allows for only coarse grained transformations.\n",
    "\n",
    "This knowledge gave us some insight into how to interact with our dataframe.  So we saw that to select specific columns, we have to use the `select` method, which operates as a `transformation` and then use the `show` method as our action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "compatible-patrol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|               title|    genre|\n",
      "+--------------------+---------+\n",
      "|             Shazam!|   Comedy|\n",
      "|      Captain Marvel|   Action|\n",
      "|         Escape Room|   Horror|\n",
      "|How to Train A Dr...|Animation|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select(['title', 'genre']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-investigator",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Pyspark operations](https://hendra-herviawan.github.io/)\n",
    "\n",
    "[Pyspark DataFrame Rows and Columns](https://hendra-herviawan.github.io/pyspark-dataframe-row-columns.html)\n",
    "\n",
    "[Creating a Dataframe](https://neapowers.com/pyspark/createdataframe-todf/)\n",
    "\n",
    "[Spark by Examples](https://sparkbyexamples.com/pyspark-tutorial/#pyspark-dataframe)\n",
    "\n",
    "[Data Partitioning Spark](https://kontext.tech/column/spark/296/data-partitioning-in-spark-pyspark-in-depth-walkthrough)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-religion",
   "metadata": {},
   "source": [
    "[DataBricks RDD to Dataframe](https://databricks.com/glossary/what-is-rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-circumstances",
   "metadata": {},
   "source": [
    "[DataFrame Programming Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
