{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-webcam",
   "metadata": {},
   "source": [
    "### Putting it Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-highlight",
   "metadata": {},
   "source": [
    "Let's not put together our understanding of transformations and actions with what we see in the Spark UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-angle",
   "metadata": {},
   "source": [
    "1. Spark Jobs \n",
    "\n",
    "So remember that Spark transformations do not actually act on our data, whereas actions do.  This means, if we look at our Spark UI, we'll see that the number Spark jobs is equal to the number of actions that we execute.  So if we simply call `movies_rdd.take(1)`, this kicks off a spark job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-commander",
   "metadata": {},
   "source": [
    "2. Spark Stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-shift",
   "metadata": {},
   "source": [
    "We saw that a single job may have multiple stages.  We can think of our stages as a logical group of steps that can be completed at once.  For us our stages are divided into steps that can be performed before a shuffle, and then steps that can be performed after a shuffle.\n",
    "\n",
    "For example, let's create a spark context and perform a groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "passive-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"films\").setMaster(\"local[2]\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-wisdom",
   "metadata": {},
   "source": [
    "> And then create an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "elegant-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = ['dark knight', 'dunkirk', 'pulp fiction', 'avatar']\n",
    "movies_rdd = sc.parallelize(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "textile-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D', 2), ('P', 1), ('A', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_rdd.map(lambda word: word.title()). \\\n",
    "groupBy(lambda title: title[0]). \\\n",
    "map(lambda group: (group[0], len(group[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-first",
   "metadata": {},
   "source": [
    "We can see that the first stage involved reading the file, and grouping together the data.  This is often called the `ShuffleMap` Stage.  Because it's where our shuffling and mapping occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-thesis",
   "metadata": {},
   "source": [
    "<img src=\"./preshuffle.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-continent",
   "metadata": {},
   "source": [
    "And then once our data was grouped together properly, Spark could prepare the final results of counting the number of movies by record."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-lancaster",
   "metadata": {},
   "source": [
    "<img src=\"./resultstage.png\" width=\"35%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-madonna",
   "metadata": {},
   "source": [
    "3. Spark Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-jungle",
   "metadata": {},
   "source": [
    "Each task is a stage performed on a partition of a data.  So a stage can have multiple tasks, because it generally occurs in parallel across multiple data partitions.  So when we look in the event timeline of Spark, we see that the same steps occurred across multiple partitions, with one task per partition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-jurisdiction",
   "metadata": {},
   "source": [
    "<img src=\"./tasks.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-enhancement",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-strain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
