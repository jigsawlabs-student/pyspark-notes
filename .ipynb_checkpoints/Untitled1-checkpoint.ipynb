{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "neural-correspondence",
   "metadata": {},
   "source": [
    "### Spark Context Again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-upset",
   "metadata": {},
   "source": [
    "So above, we create the SparkContext by specifying the information needed to connect to our spark cluster.  Let's walk through the steps to doing so.\n",
    "\n",
    "First, we set up some configuration for the spark session.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "continuous-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"films\").setMaster(\"local[2]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-luther",
   "metadata": {},
   "source": [
    "Now above, we call `SparkConf().setAppName(\"films\")` to set up our application name, which is just a name that we specify.  And then we use the `setMaster(\"local[2]\")` method to specify the location of the cluster we want to connect to.  Generally, we'll pass in the url to specify this location, but above we are connecting to the cluster on our local computer so we just use the string `\"local\"`.  The square brackets are there to indicate the number of parallel proccesses we want running -- that is the number of cores allocated to our spark cluster.  \n",
    "\n",
    "> If we want to use as many cores as are available on our computer we can use `\"local[*]\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-section",
   "metadata": {},
   "source": [
    "Now that we've created the *configuration* for our Spark Context, the next step is to call the `SparkContext.getOrCreate` method to actually create that new context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "surgical-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-analyst",
   "metadata": {},
   "source": [
    "That's it, our Spark Context is all set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "boring-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jeffreys-air.home:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>films</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=films>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
